from selenium import webdriver
from selenium.webdriver.chrome.service import Service as ChromeService
from webdriver_manager.chrome import ChromeDriverManager
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from openpyxl import Workbook

# 使用 ChromeDriverManager 自动管理 ChromeDriver
service = ChromeService(ChromeDriverManager().install())
driver = webdriver.Chrome(service=service)

try:
    # 打开目标网页
    driver.get("https://www.aroma-zone.com/recipes/recipe-list")

    # 创建 Excel 工作簿
    wb = Workbook()
    ws = wb.active
    ws.append(["Title", "Link"])  # 写入标题行


    # 定义一个函数来抓取页面数据
    def scrape_page_data():
        results = driver.find_elements(By.CSS_SELECTOR, "div.recipe-card")
        for result in results:
            title_element = result.find_element(By.CSS_SELECTOR, "span")
            link_element = result.find_element(By.CSS_SELECTOR, "a")
            title = title_element.text
            link = link_element.get_attribute("href")
            ws.append([title, link])


    # 抓取第一页数据
    scrape_page_data()

    # 循环跳转到第二页和第9页
    for page in range(2, 10):  # 从2跳转到3
        # 构造分页URL
        driver.execute_script(f"window.location.href = 'https://www.aroma-zone.com/recipes/recipe-list?page={page}';")

        # 等待页面加载完成
        WebDriverWait(driver, 15).until(
            EC.presence_of_element_located((By.CSS_SELECTOR, "div.recipe-card"))
        )

        # 抓取页面数据
        scrape_page_data()

    # 保存 Excel 文件
    wb.save("search_aroma.xlsx")

finally:
    # 关闭浏览器
    driver.quit()
